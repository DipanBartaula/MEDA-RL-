import os
import argparse
import torch
from model import CADPolicy
from renderer import run_cad_code, render_orthographic
from PIL import Image
import numpy as np

def parse_args():
    p = argparse.ArgumentParser()
    p.add_argument('--checkpoint', type=str, required=True)
    p.add_argument('--prompts',    type=str, required=True)
    p.add_argument('--output-dir', type=str, default='./inference')
    p.add_argument('--max-length', type=int, default=128)
    return p.parse_args()

def load_prompts(arg):
    if os.path.isfile(arg):
        return [l.strip() for l in open(arg) if l.strip()]
    return [arg]

def main():
    args = parse_args()
    os.makedirs(args.output_dir, exist_ok=True)

    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    policy = CADPolicy(device=device)
    state = torch.load(args.checkpoint, map_location=device)
    policy.model.load_state_dict(state)
    policy.model.eval()

    prompts = load_prompts(args.prompts)
    for i, prompt in enumerate(prompts, 1):
        print(f"[{i}] {prompt}")
        code = policy.generate(prompt, max_length=args.max_length)

        cf = os.path.join(args.output_dir, f'code_{i:03d}.py')
        with open(cf, 'w') as f:
            f.write("# Generated by CADPolicy\n# Prompt: " + prompt + "\n\n" + code)

        try:
            mesh = run_cad_code(code)
            mf = os.path.join(args.output_dir, f'mesh_{i:03d}.stl')
            mesh.export(mf)

            rend = render_orthographic(mesh)
            img = Image.fromarray((rend * 255).astype(np.uint8))
            rf = os.path.join(args.output_dir, f'render_{i:03d}.png')
            img.save(rf)

            print(f" → code: {cf}, mesh: {mf}, render: {rf}")
        except Exception as e:
            print(f" ✗ failed: {e}")

if __name__ == "__main__":
    main()
